{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yysyF_flt5zk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.listdir('/content/drive/MyDrive')\n"
      ],
      "metadata": {
        "id": "QV_gi4WmuSdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification dataset\n",
        "DATASET1_PATH = \"/content/drive/MyDrive/dataset1\"\n",
        "\n",
        "# Detection dataset\n",
        "DATASET2_IMAGES = \"/content/drive/MyDrive/dataset2/images\"\n",
        "DATASET2_ANN = \"/content/drive/MyDrive/dataset2/annotations\"\n"
      ],
      "metadata": {
        "id": "oDP0O5cHuS1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/dataset1\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "for split in splits:\n",
        "    print(f\"\\n{split.upper()}\")\n",
        "    for cls in sorted(os.listdir(os.path.join(base_path, split))):\n",
        "        cls_path = os.path.join(base_path, split, cls)\n",
        "        if os.path.isdir(cls_path):\n",
        "            print(f\"{cls}: {len(os.listdir(cls_path))} images\")\n"
      ],
      "metadata": {
        "id": "18iOnxR5uVyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "tbi4MoWvubQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = ImageFolder(root=f\"{base_path}/train\", transform=train_tfms)\n",
        "val_ds   = ImageFolder(root=f\"{base_path}/val\",   transform=val_tfms)\n",
        "test_ds  = ImageFolder(root=f\"{base_path}/test\",  transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=16, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=16, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "9WwzPGblufh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.class_to_idx)\n"
      ],
      "metadata": {
        "id": "FRQKgC1nukOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "model = timm.create_model(\n",
        "    \"swin_tiny_patch4_window7_224\",\n",
        "    pretrained=True,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "Hh6_f32OunDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=3e-4,          # baseline LR (GWO will tune later)\n",
        "    weight_decay=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "0Cgz_P0pvk0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    return running_loss / len(loader), acc\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    return running_loss / len(loader), acc\n"
      ],
      "metadata": {
        "id": "e4AYFuX2uy4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50   # baseline, keep small\n",
        "\n",
        "best_val_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion\n",
        "    )\n",
        "    val_loss, val_acc = validate(\n",
        "        model, val_loader, criterion\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
        "        f\"Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Acc: {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_swin_baseline.pth\")\n"
      ],
      "metadata": {
        "id": "HLsDQ_Umu5_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_swin_baseline.pth\"))\n",
        "test_loss, test_acc = validate(model, test_loader, criterion)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "j9adIZAiwbJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Baseline Swin Training (No GWO)\n"
      ],
      "metadata": {
        "id": "MXBpqg-5501i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=3e-4,          # baseline learning rate\n",
        "    weight_decay=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "bbY54US54I5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / len(loader), correct / total\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / len(loader), correct / total\n"
      ],
      "metadata": {
        "id": "lhivr8GB5FwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "best_val_acc = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion\n",
        "    )\n",
        "    val_loss, val_acc = validate(\n",
        "        model, val_loader, criterion\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
        "        f\"Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Acc: {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(),\n",
        "                   \"/content/drive/MyDrive/swin_baseline_best.pth\")\n"
      ],
      "metadata": {
        "id": "RZoOHUU75Kn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/swin_baseline_best.pth\")\n",
        ")\n",
        "\n",
        "test_loss, test_acc = validate(model, test_loader, criterion)\n",
        "print(f\"Baseline Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "fzFLX_vJ5ik6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " STEP 3 â€” Swin + Grey Wolf Optimization (GWO)"
      ],
      "metadata": {
        "id": "gLBtpBYf6ISC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/swin_best_model.pth\"\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "vNZy-qOIwxlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Search ranges\n",
        "LR_RANGE = (1e-5, 5e-4)\n",
        "WD_RANGE = (1e-6, 1e-3)\n",
        "BATCH_CHOICES = [8, 16, 32]\n"
      ],
      "metadata": {
        "id": "K243qNN06Odk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness_function(lr, wd, batch_size):\n",
        "    # Dataloader with candidate batch size\n",
        "    train_loader_gwo = DataLoader(\n",
        "        train_ds, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "    val_loader_gwo = DataLoader(\n",
        "        val_ds, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    # New Swin model\n",
        "    model = timm.create_model(\n",
        "        \"swin_tiny_patch4_window7_224\",\n",
        "        pretrained=True,\n",
        "        num_classes=NUM_CLASSES\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(), lr=lr, weight_decay=wd\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train for few epochs\n",
        "    for _ in range(2):\n",
        "        train_one_epoch(model, train_loader_gwo, optimizer, criterion)\n",
        "\n",
        "    _, val_acc = validate(model, val_loader_gwo, criterion)\n",
        "\n",
        "    return val_acc\n"
      ],
      "metadata": {
        "id": "Lddghs7s6aNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WOLVES = 5\n",
        "\n",
        "wolves = []\n",
        "for _ in range(NUM_WOLVES):\n",
        "    wolf = {\n",
        "        \"lr\": random.uniform(*LR_RANGE),\n",
        "        \"wd\": random.uniform(*WD_RANGE),\n",
        "        \"batch\": random.choice(BATCH_CHOICES)\n",
        "    }\n",
        "    wolves.append(wolf)\n"
      ],
      "metadata": {
        "id": "4DbAMqUx6e4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ITER = 3   # keep small for Colab\n",
        "\n",
        "alpha = beta = delta = None\n",
        "\n",
        "for iter in range(NUM_ITER):\n",
        "    print(f\"\\nGWO Iteration {iter+1}\")\n",
        "\n",
        "    fitness_scores = []\n",
        "\n",
        "    for wolf in wolves:\n",
        "        acc = fitness_function(\n",
        "            wolf[\"lr\"], wolf[\"wd\"], wolf[\"batch\"]\n",
        "        )\n",
        "        fitness_scores.append(acc)\n",
        "        print(wolf, \"Acc:\", acc)\n",
        "\n",
        "    # Sort wolves by fitness\n",
        "    sorted_wolves = [\n",
        "        w for _, w in sorted(\n",
        "            zip(fitness_scores, wolves),\n",
        "            key=lambda x: x[0],\n",
        "            reverse=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    alpha, beta, delta = sorted_wolves[:3]\n",
        "\n",
        "    # Update wolves (simplified update rule)\n",
        "    for wolf in wolves:\n",
        "        wolf[\"lr\"] = (wolf[\"lr\"] + alpha[\"lr\"]) / 2\n",
        "        wolf[\"wd\"] = (wolf[\"wd\"] + alpha[\"wd\"]) / 2\n",
        "        wolf[\"batch\"] = alpha[\"batch\"]\n"
      ],
      "metadata": {
        "id": "8zqUggBR6iKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBest Hyperparameters (Alpha Wolf):\")\n",
        "print(alpha)\n"
      ],
      "metadata": {
        "id": "8WCPIPBx7rbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=alpha[\"lr\"],\n",
        "    weight_decay=alpha[\"wd\"]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=alpha[\"batch\"], shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=alpha[\"batch\"], shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "45fOVCV87yAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " STEP 4 â€” Model Evaluation (Test Accuracy + Confusion Matrix)"
      ],
      "metadata": {
        "id": "yRMI7-418EIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "model = timm.create_model(\n",
        "    \"swin_tiny_patch4_window7_224\",\n",
        "    pretrained=False,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/swin_baseline_best.pth\"\n",
        "# (or swin_gwo_best.pth if using GWO)\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "vPCFETdq8JcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "H2eQwqcX8T4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_acc = accuracy_score(y_true, y_pred)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "WAGETKtH8ZHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "class_names = train_ds.classes\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names\n",
        ")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - Swin Transformer\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gbK_oebE8ePM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "for i, acc in enumerate(per_class_acc):\n",
        "    print(f\"{class_names[i]}: {acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "4kLGkLBy8wNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 5 â€” Final Integrated Leaf Disease System"
      ],
      "metadata": {
        "id": "b4N62kUN9BUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "swin_model = timm.create_model(\n",
        "    \"swin_tiny_patch4_window7_224\",\n",
        "    pretrained=False,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "\n",
        "swin_model.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/swin_baseline_best.pth\",\n",
        "               map_location=device)\n",
        ")\n",
        "swin_model = swin_model.to(device)\n",
        "swin_model.eval()\n"
      ],
      "metadata": {
        "id": "0xYH6GnJ9GaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "det_model = fasterrcnn_resnet50_fpn(\n",
        "    pretrained=False,\n",
        "    num_classes=2   # background + disease\n",
        ")\n",
        "\n",
        "det_model.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/faster_rcnn_leaf.pth\",\n",
        "               map_location=device)\n",
        ")\n",
        "\n",
        "det_model = det_model.to(device)\n",
        "det_model.eval()\n"
      ],
      "metadata": {
        "id": "eU6jlnhx9P4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "cls_tfms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "class_names = train_ds.classes  # same order as training\n",
        "\n",
        "def classify_leaf(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = cls_tfms(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = swin_model(img)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        conf, pred = torch.max(probs, 1)\n",
        "\n",
        "    return class_names[pred.item()], conf.item()\n"
      ],
      "metadata": {
        "id": "bzQwJDFZ9Zbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "det_tfms = T.Compose([T.ToTensor()])\n",
        "\n",
        "def detect_regions(image_path, score_thresh=0.5):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = det_tfms(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = det_model([img_tensor])[0]\n",
        "\n",
        "    boxes = prediction[\"boxes\"]\n",
        "    scores = prediction[\"scores\"]\n",
        "\n",
        "    keep = scores >= score_thresh\n",
        "    boxes = boxes[keep]\n",
        "\n",
        "    return boxes, img.size\n"
      ],
      "metadata": {
        "id": "9NbWPsrG9dcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_severity(boxes, img_size):\n",
        "    img_w, img_h = img_size\n",
        "    img_area = img_w * img_h\n",
        "\n",
        "    infected_area = 0.0\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        infected_area += ((x2 - x1) * (y2 - y1)).item()\n",
        "\n",
        "    severity = infected_area / img_area if img_area > 0 else 0.0\n",
        "    return float(severity)\n"
      ],
      "metadata": {
        "id": "3kqOHwWR9gAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_lifespan(num_boxes, severity):\n",
        "    base_life = 100  # days (healthy leaf)\n",
        "\n",
        "    lifespan = base_life \\\n",
        "               - (num_boxes * 10) \\\n",
        "               - (severity * 50)\n",
        "\n",
        "    return max(int(lifespan), 10)\n"
      ],
      "metadata": {
        "id": "XwtJZ_309ihH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_leaf_analysis(image_path):\n",
        "    # 1ï¸âƒ£ Disease classification\n",
        "    disease, confidence = classify_leaf(image_path)\n",
        "\n",
        "    # 2ï¸âƒ£ Localization\n",
        "    boxes, img_size = detect_regions(image_path)\n",
        "    num_boxes = len(boxes)\n",
        "\n",
        "    # 3ï¸âƒ£ Severity\n",
        "    severity = compute_severity(boxes, img_size)\n",
        "\n",
        "    # 4ï¸âƒ£ Lifespan\n",
        "    lifespan = estimate_lifespan(num_boxes, severity)\n",
        "\n",
        "    return {\n",
        "        \"Disease\": disease,\n",
        "        \"Confidence (%)\": round(confidence * 100, 2),\n",
        "        \"Infected Regions\": num_boxes,\n",
        "        \"Severity Score\": round(severity, 3),\n",
        "        \"Estimated Leaf Lifespan (days)\": lifespan\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Js8nELKp9j9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf2.jpg\"\n",
        "\n",
        "result = full_leaf_analysis(image_path)\n",
        "\n",
        "for k, v in result.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ],
      "metadata": {
        "id": "y9bO9elL9sD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Draw Bounding Boxes on Leaf Image (Faster Râ€‘CNN Output)"
      ],
      "metadata": {
        "id": "4tA4W07Q-Zcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "\n",
        "det_tfms = T.Compose([T.ToTensor()])\n",
        "\n",
        "def show_bounding_boxes(image_path, score_thresh=0.5):\n",
        "    # Load image\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = det_tfms(img).to(device)\n",
        "\n",
        "    # Faster R-CNN inference\n",
        "    with torch.no_grad():\n",
        "        prediction = det_model([img_tensor])[0]\n",
        "\n",
        "    boxes = prediction[\"boxes\"]\n",
        "    scores = prediction[\"scores\"]\n",
        "\n",
        "    # Filter by confidence\n",
        "    keep = scores >= score_thresh\n",
        "    boxes = boxes[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    for box, score in zip(boxes, scores):\n",
        "        x1, y1, x2, y2 = box.cpu().numpy()\n",
        "        width = x2 - x1\n",
        "        height = y2 - y1\n",
        "\n",
        "        rect = patches.Rectangle(\n",
        "            (x1, y1),\n",
        "            width,\n",
        "            height,\n",
        "            linewidth=2,\n",
        "            edgecolor='red',\n",
        "            facecolor='none'\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(\n",
        "            x1, y1 - 5,\n",
        "            f\"{score:.2f}\",\n",
        "            color='red',\n",
        "            fontsize=10,\n",
        "            backgroundcolor=\"white\"\n",
        "        )\n",
        "\n",
        "    ax.set_title(\"Detected Diseased Regions\")\n",
        "    ax.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "23qSRQcW25Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf2.jpg\"\n",
        "show_bounding_boxes(image_path)\n"
      ],
      "metadata": {
        "id": "vA1xHqB8-e2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "\n",
        "det_tfms = T.Compose([T.ToTensor()])\n",
        "\n",
        "def show_boxes_with_disease(image_path, score_thresh=0.5):\n",
        "    # ---------- Swin Prediction ----------\n",
        "    disease, confidence = classify_leaf(image_path)\n",
        "\n",
        "    # ---------- Faster R-CNN Prediction ----------\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = det_tfms(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = det_model([img_tensor])[0]\n",
        "\n",
        "    boxes = prediction[\"boxes\"]\n",
        "    scores = prediction[\"scores\"]\n",
        "\n",
        "    keep = scores >= score_thresh\n",
        "    boxes = boxes[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    # ---------- Plot ----------\n",
        "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    for box, score in zip(boxes, scores):\n",
        "        x1, y1, x2, y2 = box.cpu().numpy()\n",
        "        rect = patches.Rectangle(\n",
        "            (x1, y1),\n",
        "            x2 - x1,\n",
        "            y2 - y1,\n",
        "            linewidth=2,\n",
        "            edgecolor=\"red\",\n",
        "            facecolor=\"none\"\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(\n",
        "            x1, y1 - 5,\n",
        "            f\"{score:.2f}\",\n",
        "            color=\"red\",\n",
        "            fontsize=9,\n",
        "            backgroundcolor=\"white\"\n",
        "        )\n",
        "\n",
        "    # Disease name on top\n",
        "    ax.text(\n",
        "        10, 30,\n",
        "        f\"Disease: {disease} ({confidence*100:.2f}%)\",\n",
        "        fontsize=14,\n",
        "        color=\"white\",\n",
        "        bbox=dict(facecolor=\"black\", alpha=0.7)\n",
        "    )\n",
        "\n",
        "    ax.set_title(\"Leaf Disease Detection & Localization\")\n",
        "    ax.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4PgBgIE7-i8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf2.jpg\"\n",
        "show_boxes_with_disease(image_path)\n"
      ],
      "metadata": {
        "id": "KB7aqYqz_shl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "\n",
        "det_tfms = T.Compose([T.ToTensor()])\n",
        "\n",
        "def show_boxes_disease_lifespan(image_path, score_thresh=0.5):\n",
        "    # ---------- Swin Prediction ----------\n",
        "    disease, confidence = classify_leaf(image_path)\n",
        "\n",
        "    # ---------- Faster R-CNN Prediction ----------\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = det_tfms(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = det_model([img_tensor])[0]\n",
        "\n",
        "    boxes = prediction[\"boxes\"]\n",
        "    scores = prediction[\"scores\"]\n",
        "\n",
        "    keep = scores >= score_thresh\n",
        "    boxes = boxes[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    num_boxes = len(boxes)\n",
        "\n",
        "    # ---------- Severity ----------\n",
        "    img_w, img_h = img.size\n",
        "    img_area = img_w * img_h\n",
        "\n",
        "    infected_area = 0.0\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        infected_area += ((x2 - x1) * (y2 - y1)).item()\n",
        "\n",
        "    severity = infected_area / img_area if img_area > 0 else 0.0\n",
        "\n",
        "    # ---------- Lifespan ----------\n",
        "    base_life = 100\n",
        "    lifespan = base_life - (num_boxes * 10) - (severity * 50)\n",
        "    lifespan = max(int(lifespan), 10)\n",
        "\n",
        "    # ---------- Plot ----------\n",
        "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    # ðŸ”´ Draw THICK bounding boxes\n",
        "    for box, score in zip(boxes, scores):\n",
        "        x1, y1, x2, y2 = box.cpu().numpy()\n",
        "        rect = patches.Rectangle(\n",
        "            (x1, y1),\n",
        "            x2 - x1,\n",
        "            y2 - y1,\n",
        "            linewidth=4,          # ðŸ”¥ THICKER BOX\n",
        "            edgecolor=\"red\",\n",
        "            facecolor=\"none\"\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(\n",
        "            x1, y1 - 8,\n",
        "            f\"{score:.2f}\",\n",
        "            color=\"red\",\n",
        "            fontsize=11,\n",
        "            fontweight=\"bold\",\n",
        "            backgroundcolor=\"white\"\n",
        "        )\n",
        "\n",
        "    # ---------- Text Overlay ----------\n",
        "    ax.text(\n",
        "        10, 30,\n",
        "        f\"Disease: {disease} ({confidence*100:.2f}%)\",\n",
        "        fontsize=14,\n",
        "        color=\"white\",\n",
        "        bbox=dict(facecolor=\"black\", alpha=0.75)\n",
        "    )\n",
        "\n",
        "    ax.text(\n",
        "        10, 65,\n",
        "        f\"Infected Regions: {num_boxes}\",\n",
        "        fontsize=12,\n",
        "        color=\"white\",\n",
        "        bbox=dict(facecolor=\"black\", alpha=0.75)\n",
        "    )\n",
        "\n",
        "    ax.text(\n",
        "        10, 100,\n",
        "        f\"Estimated Leaf Lifespan: {lifespan} days\",\n",
        "        fontsize=12,\n",
        "        color=\"white\",\n",
        "        bbox=dict(facecolor=\"black\", alpha=0.75)\n",
        "    )\n",
        "\n",
        "    ax.set_title(\"Leaf Disease Detection\")\n",
        "    ax.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ELbGlUkf_wH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf2.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "BKaEkaW1AIZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf6.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "I5J5EPmsBMJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SWIN_MODEL_PATH = \"/content/drive/MyDrive/swin_final_model.pth\"\n",
        "torch.save(swin_model.state_dict(), SWIN_MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "kfdlNEydBV5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Models"
      ],
      "metadata": {
        "id": "9lepYqUpPkmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "pnlOA5r5Pxrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "NUM_CLASSES = 7\n",
        "\n",
        "swin_model = timm.create_model(\n",
        "    \"swin_tiny_patch4_window7_224\",\n",
        "    pretrained=False,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "\n",
        "swin_model.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/swin_final_model.pth\",\n",
        "               map_location=device)\n",
        ")\n",
        "\n",
        "swin_model = swin_model.to(device)\n",
        "swin_model.eval()\n"
      ],
      "metadata": {
        "id": "FqnlFK61Du59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FRCNN_MODEL_PATH = \"/content/drive/MyDrive/faster_rcnn_leaf_final.pth\"\n",
        "torch.save(det_model.state_dict(), FRCNN_MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "SdpDC5ZWDyKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "\n",
        "det_model = fasterrcnn_resnet50_fpn(\n",
        "    pretrained=False,\n",
        "    num_classes=2  # background + disease\n",
        ")\n",
        "\n",
        "det_model.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/faster_rcnn_leaf_final.pth\",\n",
        "               map_location=device)\n",
        ")\n",
        "\n",
        "det_model = det_model.to(device)\n",
        "det_model.eval()\n"
      ],
      "metadata": {
        "id": "SykmC_N9D1hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class_names = train_ds.classes\n",
        "\n",
        "with open(\"/content/drive/MyDrive/class_names.json\", \"w\") as f:\n",
        "    json.dump(class_names, f)\n"
      ],
      "metadata": {
        "id": "eXGZir6lD4Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/class_names.json\", \"r\") as f:\n",
        "    class_names = json.load(f)\n"
      ],
      "metadata": {
        "id": "D9-gpGPUEK5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " METRICS"
      ],
      "metadata": {
        "id": "sYOtzvIrF_8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_list = []\n",
        "val_acc_list = []\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n"
      ],
      "metadata": {
        "id": "vNeHpJ4fEN_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion\n",
        "    )\n",
        "    val_loss, val_acc = validate(\n",
        "        model, val_loader, criterion\n",
        "    )\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "    val_loss_list.append(val_loss)\n",
        "    train_acc_list.append(train_acc)\n",
        "    val_acc_list.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "          f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "RyuJTDYxGEsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_acc_list, label=\"Train Accuracy\")\n",
        "plt.plot(val_acc_list, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_KZV9DXvGGv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(train_loss_list, label=\"Train Loss\")\n",
        "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EpSo1z-tGj3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "YnzCMRbfGne_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(y_true, y_pred, average=None)\n",
        "recall = recall_score(y_true, y_pred, average=None)\n",
        "f1 = f1_score(y_true, y_pred, average=None)\n"
      ],
      "metadata": {
        "id": "2t_mT1GhGxwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(class_names, precision)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision per Class\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fv5kbnlQG0sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(class_names, recall)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall per Class\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PsaQJi0UG4cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(class_names, f1)\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.title(\"F1 Score per Class\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wbme6FcSG9T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf9.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "eInnZ0iOHAaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf6.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "GUaENbSHJxpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf2.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "7_0SXtdxKoLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img4.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "0XXVhBRvMSRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img6.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "-K-pYsz5Qa-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img7.jpg\"\n",
        "show_boxes_disease_lifespan(image_path)\n"
      ],
      "metadata": {
        "id": "CDtTbYKjRKkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model and predict"
      ],
      "metadata": {
        "id": "kH_H4sSGSMvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "xZgNO6bqZnxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n"
      ],
      "metadata": {
        "id": "03DOfXe3Sk7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "metadata": {
        "id": "kW4j0B9ESnmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "    \"bacterial_spot\",\n",
        "    \"brown_rust\",\n",
        "    \"early_blight\",\n",
        "    \"grey_spot\",\n",
        "    \"healthy\",\n",
        "    \"mild_dew\",\n",
        "    \"red_rot\"\n",
        "]\n",
        "\n",
        "NUM_CLASSES = len(class_names)\n"
      ],
      "metadata": {
        "id": "7LbjXEbLUn29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swin_model = timm.create_model(\n",
        "    \"swin_tiny_patch4_window7_224\",\n",
        "    pretrained=False,\n",
        "    num_classes=NUM_CLASSES\n",
        ")\n",
        "\n",
        "swin_model.load_state_dict(\n",
        "    torch.load(\n",
        "        \"/content/drive/MyDrive/swin_final_model.pth\",\n",
        "        map_location=device\n",
        "    )\n",
        ")\n",
        "\n",
        "swin_model = swin_model.to(device)\n",
        "swin_model.eval()\n",
        "\n",
        "print(\"âœ… Swin model loaded\")\n"
      ],
      "metadata": {
        "id": "F0wGUQaOSpTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "det_model = fasterrcnn_resnet50_fpn(\n",
        "    pretrained=False,\n",
        "    num_classes=2   # background + disease\n",
        ")\n",
        "\n",
        "det_model.load_state_dict(\n",
        "    torch.load(\n",
        "        \"/content/drive/MyDrive/faster_rcnn_leaf_final.pth\",\n",
        "        map_location=device\n",
        "    )\n",
        ")\n",
        "\n",
        "det_model = det_model.to(device)\n",
        "det_model.eval()\n",
        "\n",
        "print(\"âœ… Faster R-CNN model loaded\")\n"
      ],
      "metadata": {
        "id": "qFBXuE2ySr3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Swin (classification)\n",
        "cls_tfms = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# For Faster R-CNN (detection)\n",
        "det_tfms = T.Compose([T.ToTensor()])\n"
      ],
      "metadata": {
        "id": "zra8G-AwSuaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_leaf(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = cls_tfms(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = swin_model(img)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        conf, pred = torch.max(probs, 1)\n",
        "\n",
        "    return class_names[pred.item()], conf.item()\n"
      ],
      "metadata": {
        "id": "b9uXJiLsS2Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_leaf(image_path, score_thresh=0.5):\n",
        "    # ---- Swin Prediction ----\n",
        "    disease, confidence = classify_leaf(image_path)\n",
        "\n",
        "    # ---- Faster R-CNN Prediction ----\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = det_tfms(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = det_model([img_tensor])[0]\n",
        "\n",
        "    boxes = pred[\"boxes\"]\n",
        "    scores = pred[\"scores\"]\n",
        "\n",
        "    keep = scores >= score_thresh\n",
        "    boxes = boxes[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    num_boxes = len(boxes)\n",
        "\n",
        "    # ---- Severity & Lifespan ----\n",
        "    img_w, img_h = img.size\n",
        "    img_area = img_w * img_h\n",
        "\n",
        "    infected_area = 0.0\n",
        "    for b in boxes:\n",
        "        x1, y1, x2, y2 = b\n",
        "        infected_area += ((x2 - x1) * (y2 - y1)).item()\n",
        "\n",
        "    severity = infected_area / img_area if img_area > 0 else 0.0\n",
        "    lifespan = max(int(100 - num_boxes*10 - severity*50), 10)\n",
        "\n",
        "    # ---- Visualization ----\n",
        "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box.cpu().numpy()\n",
        "        rect = patches.Rectangle(\n",
        "            (x1, y1),\n",
        "            x2 - x1,\n",
        "            y2 - y1,\n",
        "            linewidth=4,\n",
        "            edgecolor=\"red\",\n",
        "            facecolor=\"none\"\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    ax.text(\n",
        "        10, 30,\n",
        "        f\"Disease: {disease} ({confidence*100:.2f}%)\",\n",
        "        fontsize=14,\n",
        "        color=\"white\",\n",
        "        bbox=dict(facecolor=\"black\", alpha=0.75)\n",
        "    )\n",
        "    ax.text(\n",
        "        10, 65,\n",
        "        f\"Infected Regions: {num_boxes}\",\n",
        "        fontsize=12,\n",
        "        color=\"white\",\n",
        "        bbox=dict(facecolor=\"black\", alpha=0.75)\n",
        "    )\n",
        "    ax.text(\n",
        "        10, 100,\n",
        "        f\"Estimated Lifespan: {lifespan} days\",\n",
        "        fontsize=12,\n",
        "        color=\"white\",\n",
        "        bbox=dict(facecolor=\"black\", alpha=0.75)\n",
        "    )\n",
        "\n",
        "    ax.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "gZGEx8xqS4Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img17.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "cGS-SvX1aeXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img18.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "KF2EJytKe32s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img23.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "_suJOTxZnAR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img25.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "7bQ2X0jV3hAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img28.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "7i44Y6iD5po_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/2 img.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "IFlWJLuG8HWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img31.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "VYbEiirL8ukX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img32.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "YiGU1iNb_QRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/images (29).jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "EW8FxmG8CUAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img36.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "Rv8h2LpYDLP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/image (16).jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "0sBGeJYIFuyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img38.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "R_t5kAfcKV-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf0.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "P1VyDApqMmmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leaf.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "Gk31eTnENFsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/blight2.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "afGzRZahP5M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/blight3.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "nOk61wV4QmmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/rot1.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "EeBfWklVUScD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/rot3.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "hfLKYUwKU4ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/img18.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "BRW-T4DdZ8v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/leafs.jpg\"\n",
        "predict_leaf(image_path)\n"
      ],
      "metadata": {
        "id": "cpSzS6iZo_u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/red rot.jpg\"\n",
        "predict_leaf(image_path)"
      ],
      "metadata": {
        "id": "WJ8I1Z-kqAR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqE-f6-orOV5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}